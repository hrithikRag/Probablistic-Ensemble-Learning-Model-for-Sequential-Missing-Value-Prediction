{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da51841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.autonotebook import tqdm\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "path_dir = Path('D:/Workspace/Projects/BayesianLearning/Project1_Data/CSV')\n",
    "path=\"D:/Workspace/Projects/BayesianLearning/Project1_Data/CSV/\"\n",
    "list_dfs = []\n",
    "for path_file in path_dir.glob('Node_*.csv'):\n",
    "    df_small = pd.read_csv(path_file)\n",
    "    list_dfs.append(df_small)\n",
    "    \n",
    "df = pd.concat(list_dfs, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d/%m/00%y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialT=df.sort_values(by=['timestamp'], ascending=True)\n",
    "spatialT.reset_index(drop=True, inplace=True)\n",
    "spatialH=df.sort_values(by=['timestamp'], ascending=True)\n",
    "spatialH.reset_index(drop=True, inplace=True)\n",
    "start = datetime.datetime(2014, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialT.drop([\"temperature\",\"humidity\"], axis=1, inplace=True)\n",
    "spatialH.drop([\"temperature\",\"humidity\"], axis=1, inplace=True)\n",
    "spatialT['timestamp']=spatialT['timestamp']-start\n",
    "spatialT['timestamp']=spatialT['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n",
    "spatialH['timestamp']=spatialH['timestamp']-start\n",
    "spatialH['timestamp']=spatialH['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction Data Aggregator\n",
    "ID2Index = {}\n",
    "for k in tqdm([1,2,5,7,8]):\n",
    "    check=pd.read_csv(path+'Node_50'+str(k)+'.csv')\n",
    "    check['timestamp'] = pd.to_datetime(check['timestamp'], format='%d/%m/00%y %H:%M')\n",
    "    check['timestamp'] = check['timestamp']-start\n",
    "    check['timestamp'] = check['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n",
    "    spatialT['X'+str(k)] = np.nan\n",
    "    spatialH['X'+str(k)] = np.nan\n",
    "    for i in tqdm(range(spatialT.shape[0]), leave=False):\n",
    "        if spatialT.iloc[i]['ID'] not in ID2Index:\n",
    "            ID2Index[spatialT.iloc[i]['ID']]=i\n",
    "        for j in range(check.shape[0]):\n",
    "            if abs(spatialT.iloc[i]['timestamp']-check.iloc[j]['timestamp'])<=5:\n",
    "                spatialT.at[i,'X'+str(k)] = check.iloc[j]['temperature']\n",
    "                spatialH.at[i,'X'+str(k)] = check.iloc[j]['humidity']\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialT.to_csv(path+'Sessions/spatialT.csv',index=False)\n",
    "spatialH.to_csv(path+'Sessions/spatialH.csv',index=False)\n",
    "with open(path+'Sessions/ID2Index', 'wb') as handle:\n",
    "    pickle.dump(ID2Index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = Path('D:/Workspace/Projects/BayesianLearning/Project1_Data/CSV/Sessions')\n",
    "\n",
    "list_dfs = []\n",
    "for path_file in path_dir.glob('TN_50*.csv'):\n",
    "    df_small = pd.read_csv(path_file)\n",
    "    list_dfs.append(df_small)\n",
    "    \n",
    "df = pd.concat(list_dfs, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "testT=df.sort_values(by=['timestamp'], ascending=True)\n",
    "testT.reset_index(drop=True, inplace=True)\n",
    "testH=df.sort_values(by=['timestamp'], ascending=True)\n",
    "testH.reset_index(drop=True, inplace=True)\n",
    "testT['timestamp'] = pd.to_datetime(testT['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "testH['timestamp'] = pd.to_datetime(testH['timestamp'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c9a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testT.drop([\"temperature\",\"humidity\"], axis=1, inplace=True)\n",
    "testH.drop([\"temperature\",\"humidity\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b004f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "testT['timestamp']=testT['timestamp']-start\n",
    "testT['timestamp']=testT['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n",
    "testH['timestamp']=testH['timestamp']-start\n",
    "testH['timestamp']=testH['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data Aggregator\n",
    "TestID2Index = {}\n",
    "for k in tqdm([1,2,5,7,8]):\n",
    "    check=pd.read_csv(path+'Sessions/TN_50'+str(k)+'.csv')\n",
    "    check['timestamp'] = pd.to_datetime(check['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "    check['timestamp'] = check['timestamp']-start\n",
    "    check['timestamp'] = check['timestamp'].apply(lambda x: x/np.timedelta64(1, 'm')).fillna(0).astype('int64')\n",
    "    testT['X'+str(k)] = np.nan\n",
    "    testH['X'+str(k)] = np.nan\n",
    "    for i in tqdm(range(testT.shape[0]), leave=False):\n",
    "        if testT.iloc[i]['ID'] not in TestID2Index:\n",
    "            TestID2Index[testT.iloc[i]['ID']]=i\n",
    "        for j in range(check.shape[0]):\n",
    "            if abs(testT.iloc[i]['timestamp']-check.iloc[j]['timestamp'])<=5:\n",
    "                testT.at[i,'X'+str(k)] = check.iloc[j]['temperature']\n",
    "                testH.at[i,'X'+str(k)] = check.iloc[j]['humidity']\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd74b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "testT.to_csv(path+'Sessions/testT.csv',index=False)\n",
    "testH.to_csv(path+'Sessions/testH.csv',index=False)\n",
    "with open(path+'Sessions/TestID2Index', 'wb') as handle:\n",
    "    pickle.dump(TestID2Index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
